import io
import random
import string
import warnings
import numpy as np
import nltk
from nltk.stem import WordNetLemmatizer
import json
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

warnings.filterwarnings('ignore')
nltk.download('popular', quiet=True)

class VersatileChatbot:
    def __init__(self, name, corpus_file, personality_file,varbose = False):
        """
        Initialize the chatbot with the provided name, corpus file, and personality file.

        Parameters:
        - name (str): The name of the chatbot.
        - corpus_file (str): The path to the corpus file.
        - personality_file (str): The path to the personality file.
        - varbose (bool, optional): Flag indicating whether to enable verbose mode. Defaults to False.
        """
        self.name = name
        self.varbose = varbose
        self.lemmer = WordNetLemmatizer()
        self.load_corpus(corpus_file)
        self.load_personality(personality_file)
        self.load_language_model()
        

    def load_corpus(self, corpus_file):
        """
        Load the corpus file for the chatbot.

        This method loads the corpus file to be used by the chatbot. It reads the file,
        converts the text to lowercase, and tokenizes the text into sentences and words.

        Parameters:
        - corpus_file (str): The path to the corpus file to load.

        Returns: Nothing
        """
        if(self.varbose):print("loading corpus...")
        with open(corpus_file, 'r', encoding='utf8', errors='ignore') as fin:
            self.raw = fin.read().lower()
        self.sent_tokens = nltk.sent_tokenize(self.raw)
        self.word_tokens = nltk.word_tokenize(self.raw)

    def load_personality(self, personality_file):
        """
        Load the personality of the chatbot.

        This method loads the personality of the chatbot from a JSON file. The
        personality is a dictionary that contains the following keys:

        - greetings: A dictionary containing the following keys:
          - inputs: A list of strings that are the inputs to the chatbot that
            should trigger a greeting response.
          - responses: A list of strings that are the responses to the inputs.

        Parameters:
        - personality_file (str): The path to the JSON file containing the
          personality of the chatbot.

        Returns: Nothing
        """
        if(self.varbose):print("loading personality...")
        with open(personality_file, 'r') as f:
            self.personality = json.load(f)
        self.GREETING_INPUTS = tuple(self.personality['greetings']['inputs'])
        self.GREETING_RESPONSES = self.personality['greetings']['responses']

    def load_language_model(self):
        """
        Load the pre-trained language model.

        This method loads a pre-trained GPT-2 model and tokenizer. The model is
        set to evaluation mode, meaning it will not update its parameters during
        use.

        Parameters: None

        Returns: Nothing
        """
        if(self.varbose):print("loading language model...")
        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
        self.model = GPT2LMHeadModel.from_pretrained('gpt2')
        self.model.eval()

    def lem_tokens(self, tokens):
        """
        Lemmatize a list of tokens.

        Parameters:
        - tokens (list[str]): The list of tokens to lemmatize.

        Returns:
        - list[str]: The list of lemmatized tokens.
        """
        if(self.varbose):print("lemmatizing tokens...")
        return [self.lemmer.lemmatize(token) for token in tokens]

    def lem_normalize(self, text):
        """
        Normalize a string of text by lowercasing it, removing punctuation, and
        lemmatizing it.

        Parameters:
        - text (str): The input text to normalize.

        Returns:
        - normalized (list): A list of lemmatized tokens.
        """
        if(self.varbose):print("lemmatizing tokens...")
        remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)
        return self.lem_tokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

    def greeting(self, sentence):
        """
        Determine if the user's input is a greeting, and if so, generate a
        response.

        Parameters:
        - sentence (str): The input provided by the user.

        Returns:
        - response (str): The response generated by the chatbot based on the
          input, or None if the input is not a greeting.
        """
        sentence=sentence+"respond like robot assistant with only one sentence. "
        if(self.varbose):print("greeting")
        for word in sentence.split():
            if word.lower() in self.GREETING_INPUTS:
                return random.choice(self.GREETING_RESPONSES)

    def generate_response(self, user_input, max_length=400):
        """
        Generate a response based on the user's input.

        Parameters:
        - user_input (str): The input provided by the user.
        - max_length (int): The maximum length of the response.

        Returns:
        - response (str): The response generated by the chatbot based on the input.
        """
        if(self.varbose):print("generating response...")
        input_ids = self.tokenizer.encode(user_input, return_tensors='pt')
        attention_mask = torch.ones(input_ids.shape, dtype=torch.long)
        pad_token_id = self.tokenizer.eos_token_id

        with torch.no_grad():
            output = self.model.generate(
                input_ids,
                attention_mask=attention_mask,
                max_length=max_length,
                num_return_sequences=1,
                no_repeat_ngram_size=1,
                do_sample=True,
                top_k=5,
                top_p=0.97,
                temperature=0.9,
                pad_token_id=pad_token_id
            )

        response = self.tokenizer.decode(output[0], skip_special_tokens=True)
        return response[len(user_input):].strip()

    def process_input(self, user_input):
        """
        Process the user input and generate an appropriate response based on the input.
        
        Parameters:
        - user_input (str): The input provided by the user.
        
        Returns:
        - response (str): The response generated by the chatbot based on the input.
        - continue_chat (bool): A flag indicating whether the chat should continue after this response.
        """
        if self.varbose: print("processing input...")
        
        if user_input is None:
            return "Invalid input. Please try again.", True

        user_input = user_input.lower().strip()
        if not self.personality:
            raise ValueError("Personality data not loaded.")
        if 'exit_commands' not in self.personality or 'gratitude_expressions' not in self.personality:
            raise ValueError("Invalid personality structure.")

        if user_input in self.personality.get('exit_commands', []):
            return self.personality.get('exit_message', "Goodbye!"), False
        elif user_input in self.personality.get('gratitude_expressions', []):
            return self.personality.get('gratitude_response', "You're welcome!"), False
        else:
            try:
                greeting_response = self.greeting(user_input)
            except Exception as e:
                if self.varbose: print(f"Error in greeting: {e}")
                greeting_response = None

            if greeting_response:
                return greeting_response, True
            else:
                try:
                    chatbot_response = self.generate_response(user_input)
                except Exception as e:
                    if self.varbose: print(f"Error in generating response: {e}")
                    chatbot_response = "I couldn't process that. Can you say it differently?"
                return chatbot_response, True
            
    def chat_generator(self):
        """
        Generate a chat with the user.
        
        This function will print a welcome message, then enter a loop where it will
        read user input, process it, and print a response. The loop will continue
        until the user enters a command that triggers the chatbot to exit.
        
        Parameters: None
        """
        user_input = input("You: ")
        if user_input is None:
            return  # Exit the generator if user_input is None
        try:
            response, continue_chat = self.process_input(user_input)
        except Exception as e:
            print(f"Error: {e}")
            return  # Exit the generator if there's an error
        #print(f"you: {user_input}")
        print(f"{self.name}: {response}")
        if(continue_chat):
            self.chat_generator()
        
    def chat(self):
        """
        Run a chat with the user.
        
        This function will print a welcome message, then enter a loop where it will
        read user input, process it, and print a response. The loop will continue
        until the user enters a command that triggers the chatbot to exit.
        
        Parameters: None
        
        Returns: Nothing
        """
        print(f"{self.name}: {self.personality['welcome_message']}")
        self.chat_generator()


if __name__ == "__main__":
    chatbot = VersatileChatbot("Robo", "chatbot.txt", "personality.json")
    chatbot.chat()

