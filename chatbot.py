import io
import random
import string
import warnings
# pip install numpy scikit-learn nltk torch transformers
# python -m pip install numpy scikit-learn nltk torch transformers

import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from nltk.stem import WordNetLemmatizer
import json
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

warnings.filterwarnings('ignore')
nltk.download('popular', quiet=True)
nltk.download('punkt_tab', quiet=False)



class VersatileChatbot:
    def __init__(self, name, corpus_file, personality_file,varbose = False):
        """
        Initialize the chatbot with the provided name, corpus file, and personality file.

        Parameters:
        - name (str): The name of the chatbot.
        - corpus_file (str): The path to the corpus file.
        - personality_file (str): The path to the personality file.
        - varbose (bool, optional): Flag indicating whether to enable verbose mode. Defaults to False.
        """
        self.name = name
        self.varbose = varbose
        self.lemmer = WordNetLemmatizer()
        self.load_corpus(corpus_file)
        self.load_personality(personality_file)
        self.load_language_model()
        

    def load_corpus(self, corpus_file):
        """
        Load the corpus file for the chatbot.

        This method loads the corpus file to be used by the chatbot. It reads the file,
        converts the text to lowercase, and tokenizes the text into sentences and words.

        Parameters:
        - corpus_file (str): The path to the corpus file to load.

        Returns: Nothing
        """
        if(self.varbose):print("loading corpus...")
        with open(corpus_file, 'r', encoding='utf8', errors='ignore') as fin:
            self.raw = fin.read().lower()
        self.sent_tokens = nltk.sent_tokenize(self.raw)
        self.word_tokens = nltk.word_tokenize(self.raw)

    def load_personality(self, personality_file):
        """
        Load the personality of the chatbot.

        This method loads the personality of the chatbot from a JSON file. The
        personality is a dictionary that contains the following keys:

        - greetings: A dictionary containing the following keys:
          - inputs: A list of strings that are the inputs to the chatbot that
            should trigger a greeting response.
          - responses: A list of strings that are the responses to the inputs.

        Parameters:
        - personality_file (str): The path to the JSON file containing the
          personality of the chatbot.

        Returns: Nothing
        """
        if(self.varbose):print("loading personality...")
        with open(personality_file, 'r') as f:
            self.personality = json.load(f)
        self.GREETING_INPUTS = tuple(self.personality['greetings']['inputs'])
        self.GREETING_RESPONSES = self.personality['greetings']['responses']

    def load_language_model(self):
        """
        Load the pre-trained language model.

        This method loads a pre-trained GPT-2 model and tokenizer. The model is
        set to evaluation mode, meaning it will not update its parameters during
        use.

        Parameters: None

        Returns: Nothing
        """
        if(self.varbose):print("loading language model...")
        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
        self.model = GPT2LMHeadModel.from_pretrained('gpt2')
        self.model.eval()

    def lem_tokens(self, tokens):
        """
        Lemmatize a list of tokens.

        Parameters:
        - tokens (list[str]): The list of tokens to lemmatize.

        Returns:
        - list[str]: The list of lemmatized tokens.
        """
        if(self.varbose):print("lemmatizing tokens...")
        return [self.lemmer.lemmatize(token) for token in tokens]

    def lem_normalize(self, text):
        """
        Normalize a string of text by lowercasing it, removing punctuation, and
        lemmatizing it.

        Parameters:
        - text (str): The input text to normalize.

        Returns:
        - normalized (list): A list of lemmatized tokens.
        """
        if(self.varbose):print("lemmatizing tokens...")
        remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)
        return self.lem_tokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

    def greeting(self, sentence):
        """
        Determine if the user's input is a greeting, and if so, generate a
        response.

        Parameters:
        - sentence (str): The input provided by the user.

        Returns:
        - response (str): The response generated by the chatbot based on the
          input, or None if the input is not a greeting.
        """
        sentence=sentence+"respond like robot assistant with only one sentence. "
        if(self.varbose):print("greeting")
        for word in sentence.split():
            if word.lower() in self.GREETING_INPUTS:
                return random.choice(self.GREETING_RESPONSES)

    def generate_response(self, user_input, max_length=400):
        """
        Generate a response based on the user's input.

        Parameters:
        - user_input (str): The input provided by the user.
        - max_length (int): The maximum length of the response.

        Returns:
        - response (str): The response generated by the chatbot based on the input.
        """
        if(self.varbose):print("generating response...")
        input_ids = self.tokenizer.encode(user_input, return_tensors='pt')
        attention_mask = torch.ones(input_ids.shape, dtype=torch.long)
        pad_token_id = self.tokenizer.eos_token_id

        with torch.no_grad():
            output = self.model.generate(
                input_ids,
                attention_mask=attention_mask,
                max_length=max_length,
                num_return_sequences=1,
                no_repeat_ngram_size=2,
                do_sample=True,
                top_k=30,
                top_p=0.97,
                temperature=0.9,
                pad_token_id=pad_token_id
            )

        response = self.tokenizer.decode(output[0], skip_special_tokens=True)
        return response[len(user_input):].strip()

    def process_input(self, user_input):
        """
        Process the user input and generate an appropriate response based on the input.
        
        Parameters:
        - user_input (str): The input provided by the user.
        
        Returns:
        - response (str): The response generated by the chatbot based on the input.
        - continue_chat (bool): A flag indicating whether the chat should continue after this response.
        """
        if(self.varbose):print("processing input...")
        user_input = user_input.lower()
        if user_input in self.personality['exit_commands']:
            return self.personality['exit_message'], False
        elif user_input in self.personality['gratitude_expressions']:
            return self.personality['gratitude_response'], False
        else:
            greeting_response = self.greeting(user_input)
            if greeting_response:
                return greeting_response, True
            else:
                chatbot_response = self.generate_response(user_input)
                return chatbot_response, True

    def chat(self):
        """
        Run a chat with the user.
        
        This function will print a welcome message, then enter a loop where it will
        read user input, process it, and print a response. The loop will continue
        until the user enters a command that triggers the chatbot to exit.
        
        Parameters: None
        
        Returns: Nothing
        """
        print(f"{self.name}: {self.personality['welcome_message']}")
        chat_active = True
        while chat_active:
            user_input = input("You: ")
            
            response, continue_chat = self.process_input(user_input)
            print(f"you: {user_input}")
            print(f"{self.name}: {response}")
            chat_active = continue_chat
            

if __name__ == "__main__":
    chatbot = VersatileChatbot("Robo", "chatbot.txt", "personality.json")
    chatbot.chat()